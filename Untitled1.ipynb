{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba66a8d7-dbe1-4563-89fa-da25ab426bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules and create spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c4faa20-dbb7-49b6-8f96-2aca6c03da49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81762378-a188-4b01-8e57-2db6c6d2ff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Spark session\n",
    "appName = \"Sentiment Analysis in Spark\"\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(appName) \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6907be-782e-4e76-b4ec-a185841a43f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data file into Spark dataFrame\n",
    "#Role: Read the CSV file containing the tweet data into a Spark DataFrame.\n",
    "#The inferSchema=True option automatically detects the data types of the columns,\n",
    "#and header=True indicates that the first row of the CSV file contains column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1526f69-3235-4318-822c-2f581272bd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+---------------+---------------------------------+\n",
      "|ItemID|Sentiment|SentimentSource|SentimentText                    |\n",
      "+------+---------+---------------+---------------------------------+\n",
      "|1038  |1        |Sentiment140   |that film is fantastic #brilliant|\n",
      "|1804  |1        |Sentiment140   |this music is really bad #myband |\n",
      "|1693  |0        |Sentiment140   |winter is terrible #thumbs-down  |\n",
      "+------+---------+---------------+---------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#read csv file into dataFrame with automatically inferred schema\n",
    "tweets_csv = spark.read.csv('tweets.csv', inferSchema=True, header=True)\n",
    "tweets_csv.show(truncate=False, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c2ba45-ffe7-4fbe-99d4-48513cd22d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the related data\n",
    "#Role: Select only the relevant columns (SentimentText and Sentiment). \n",
    "#The Sentiment column is cast to an integer type and renamed to label, \n",
    "#which is required for the machine learning model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64c9aa80-0377-4960-925f-acd95cecfc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+-----+\n",
      "|SentimentText                    |label|\n",
      "+---------------------------------+-----+\n",
      "|that film is fantastic #brilliant|1    |\n",
      "|this music is really bad #myband |1    |\n",
      "|winter is terrible #thumbs-down  |0    |\n",
      "|this game is awful #nightmare    |0    |\n",
      "|I love jam #loveit               |1    |\n",
      "+---------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#select only \"SentimentText\" and \"Sentiment\" column, \n",
    "#and cast \"Sentiment\" column data into integer\n",
    "data = tweets_csv.select(\"SentimentText\", col(\"Sentiment\").cast(\"Int\").alias(\"label\"))\n",
    "data.show(truncate = False,n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a505540-b086-4bba-81a3-ae33f521a8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide data into training and testing data\n",
    "#Role: Select only the relevant columns (SentimentText and Sentiment).\n",
    "#The Sentiment column is cast to an integer type and renamed to label,\n",
    "#which is required for the machine learning model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08d90e06-8a2d-4010-9b4c-33d8c576a97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data rows: 1356 ; Testing data rows: 576\n"
     ]
    }
   ],
   "source": [
    "#divide data, 70% for training, 30% for testing\n",
    "dividedData = data.randomSplit([0.7, 0.3]) \n",
    "trainingData = dividedData[0] #index 0 = data training\n",
    "testingData = dividedData[1] #index 1 = data testing\n",
    "train_rows = trainingData.count()\n",
    "test_rows = testingData.count()\n",
    "print (\"Training data rows:\", train_rows, \"; Testing data rows:\", test_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c42a64c-f226-465e-b562-f4f369479885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare training data\n",
    "#Separate \"SentimentText\" into individual words using tokenizer\n",
    "#Role: Tokenize the text data by splitting sentences into individual words. \n",
    "#This is the first step in converting text data into\n",
    "#a format suitable for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dd7476e-2afe-4f02-b2a1-f76f7c6914d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-----+------------------------------+\n",
      "|SentimentText            |label|SentimentWords                |\n",
      "+-------------------------+-----+------------------------------+\n",
      "|I adore cheese #bestever |1    |[i, adore, cheese, #bestever] |\n",
      "|I adore cheese #brilliant|1    |[i, adore, cheese, #brilliant]|\n",
      "|I adore cheese #favorite |1    |[i, adore, cheese, #favorite] |\n",
      "|I adore cheese #loveit   |1    |[i, adore, cheese, #loveit]   |\n",
      "|I adore cheese #thumbs-up|1    |[i, adore, cheese, #thumbs-up]|\n",
      "+-------------------------+-----+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = Tokenizer(inputCol=\"SentimentText\", outputCol=\"SentimentWords\")\n",
    "tokenizedTrain = tokenizer.transform(trainingData)\n",
    "tokenizedTrain.show(truncate=False, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ca4015-b9c7-4832-a876-f76975643126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stop words (unimportant words to be features)\n",
    "#Role: Remove common words (stop words) that are typically not useful\n",
    "#for sentiment analysis. This helps focus on the meaningful words\n",
    "#that are more likely to indicate sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65221d7a-2cda-47c2-beb4-bca76dc4e2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-----+------------------------------+---------------------------+\n",
      "|SentimentText            |label|SentimentWords                |MeaningfulWords            |\n",
      "+-------------------------+-----+------------------------------+---------------------------+\n",
      "|I adore cheese #bestever |1    |[i, adore, cheese, #bestever] |[adore, cheese, #bestever] |\n",
      "|I adore cheese #brilliant|1    |[i, adore, cheese, #brilliant]|[adore, cheese, #brilliant]|\n",
      "|I adore cheese #favorite |1    |[i, adore, cheese, #favorite] |[adore, cheese, #favorite] |\n",
      "|I adore cheese #loveit   |1    |[i, adore, cheese, #loveit]   |[adore, cheese, #loveit]   |\n",
      "|I adore cheese #thumbs-up|1    |[i, adore, cheese, #thumbs-up]|[adore, cheese, #thumbs-up]|\n",
      "+-------------------------+-----+------------------------------+---------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "swr = StopWordsRemover(inputCol=tokenizer.getOutputCol(),outputCol=\"MeaningfulWords\")\n",
    "SwRemovedTrain = swr.transform(tokenizedTrain)\n",
    "SwRemovedTrain.show(truncate=False, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7640713-fa7e-420b-b4fd-2061cc395dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting words feature into numerical feature. In Spark 2.2.1,it is implemented \n",
    "#in HashingTF funtion using Austin Appleby's MurmurHash 3 algorithm\n",
    "#Role: Convert the meaningful words into numerical feature vectors using hashing.\n",
    "#This step is essential because machine learning models require numerical input, not text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "708151c2-5e52-40ea-9eb4-b70da60434d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------+-------------------------------------------+\n",
      "|label|MeaningfulWords            |features                                   |\n",
      "+-----+---------------------------+-------------------------------------------+\n",
      "|1    |[adore, cheese, #bestever] |(262144,[1689,91011,100089],[1.0,1.0,1.0]) |\n",
      "|1    |[adore, cheese, #brilliant]|(262144,[1689,45361,100089],[1.0,1.0,1.0]) |\n",
      "|1    |[adore, cheese, #favorite] |(262144,[1689,100089,108624],[1.0,1.0,1.0])|\n",
      "+-----+---------------------------+-------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashTF = HashingTF(inputCol=swr.getOutputCol(), outputCol=\"features\")\n",
    "numericTrainData = hashTF.transform(SwRemovedTrain).select('label', 'MeaningfulWords', 'features')\n",
    "numericTrainData.show(truncate=False, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e284481-b634-483f-a9ca-3279e3856e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train our classifier model using training data\n",
    "#Role: Train a Logistic Regression model using the training data. \n",
    "#Logistic Regression is a common algorithm for binary classification \n",
    "#tasks like sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17c717a0-a609-4c79-a2fb-1d2072806815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is done!\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10, regParam=0.01)\n",
    "model = lr.fit(numericTrainData)\n",
    "print (\"Training is done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201472b7-4912-4b67-bfbc-879319bcde91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare testing data\n",
    "#Role: Apply the same preprocessing steps\n",
    "#(tokenization, stop word removal, and feature hashing) to the testing data.\n",
    "#This ensures the test data is in the same format as the training data \n",
    "#for making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f62151c1-9691-4958-b71e-40a781786616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------------------------+-------------------------------------------------------+\n",
      "|Label|MeaningfulWords                     |features                                               |\n",
      "+-----+------------------------------------+-------------------------------------------------------+\n",
      "|1    |[adore, cheese, #toptastic]         |(262144,[1689,42010,100089],[1.0,1.0,1.0])             |\n",
      "|1    |[adore, classical, music, #bestever]|(262144,[91011,100089,102383,131250],[1.0,1.0,1.0,1.0])|\n",
      "+-----+------------------------------------+-------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizedTest = tokenizer.transform(testingData)\n",
    "SwRemovedTest = swr.transform(tokenizedTest)\n",
    "numericTest = hashTF.transform(SwRemovedTest).select('Label', 'MeaningfulWords', 'features')\n",
    "numericTest.show(truncate=False, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc907a2-9680-4388-9d1a-cdc50cec499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict testing data and calculate the accuracy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82cf3770-f12f-41f9-aa68-155ef68171d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+----------+-----+\n",
      "|MeaningfulWords                      |prediction|Label|\n",
      "+-------------------------------------+----------+-----+\n",
      "|[adore, cheese, #toptastic]          |1.0       |1    |\n",
      "|[adore, classical, music, #bestever] |1.0       |1    |\n",
      "|[adore, classical, music, #loveit]   |1.0       |1    |\n",
      "|[adore, classical, music, #toptastic]|1.0       |1    |\n",
      "|[adore, coffee, #brilliant]          |1.0       |1    |\n",
      "|[adore, coffee, #loveit]             |1.0       |1    |\n",
      "|[adore, coffee, #thumbs-up]          |1.0       |1    |\n",
      "|[adore, coffee, #toptastic]          |1.0       |1    |\n",
      "|[adore, pop, music, #loveit]         |1.0       |1    |\n",
      "|[adore, rock, music, #thumbs-up]     |1.0       |1    |\n",
      "+-------------------------------------+----------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "correct prediction: 563 , total data: 576 , accuracy: 0.9774305555555556\n"
     ]
    }
   ],
   "source": [
    "prediction = model.transform(numericTest)\n",
    "predictionFinal = prediction.select( \"MeaningfulWords\", \"prediction\", \"Label\")\n",
    "predictionFinal.show(n=10, truncate = False)\n",
    "correctPrediction = predictionFinal.filter(predictionFinal['prediction'] == predictionFinal['Label']).count()\n",
    "totalData = predictionFinal.count()\n",
    "print(\"correct prediction:\", correctPrediction, \", total data:\", totalData, \", accuracy:\", correctPrediction/totalData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb354ff3-8321-4e42-ada3-3d20bec7e1c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145684ef-de22-4503-bda1-81f51209cb5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031f73d1-46ef-432a-9e4a-cf00bf95d78d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
